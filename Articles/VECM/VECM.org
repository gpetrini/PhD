* Configs and codes :noexport:
#+PROPERTY: header-args:python :results output drawer replace :session *VECM* :exports none :tangle ./code/VECM.py :eval never-export

bibliography:ref.bib

** TODOs

**** TODO Separar os dados da estratégia empírica

** Loading packages 
#+BEGIN_SRC python
from datetime import datetime as dt

t1 = dt.now()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import matplotlib.ticker as plticker

import pandas_datareader.data as web

from scipy.interpolate import make_interp_spline, BSpline  # Smooth plot


sns.set(style="whitegrid")
# sns.set_context("paper")

plt.rc("axes", titlesize=25)  # fontsize of the axes title
plt.rcParams.update({"font.size": 20})
plt.rc("legend", fontsize=14)  # legend fontsize
plt.rc("axes", labelsize=22)  # fontsize of the x and y labels
#+END_SRC

** Save plot

#+BEGIN_SRC python
def salvar_grafico(file_name, extension="png", pasta="./figs/"):
    fig.savefig(pasta + file_name + '.' + extension, dpi = 600, bbox_inches = 'tight', format=extension,
    pad_inches = 0.2, transparent = False,)
#+END_SRC

#+RESULTS:
:results:
:end:

** Plots
*** Own houses rate of interest

#+BEGIN_SRC python :results graphics file :file ./figs/TxPropria_Investo.png
start=dt(1987,1,1)
end=dt(2019,10,1)

df = web.DataReader(
    [
        "PRFI",
        "CSUSHPISA",
        "MORTGAGE30US",
        "CPIAUCSL"
    ], 
    'fred', 
    start, 
    end
)

df.columns = [
    "Residential Investment", 
    "House Prices", 
    "Interest rate",
    "Prices"
]
df.index.name = ""


df['Interest rate'] = df['Interest rate'].divide(100)
df = df.resample('M').last()

df['House Prices'] = df['House Prices']/df['House Prices'][0]
df = df.resample('Q').last()
df["Inflation"]= df["House Prices"].pct_change()
df["General inflation"] = df["Prices"].pct_change()
df["Own interest rate"] = ((1+df["Interest rate"])/(1+df["Inflation"])) -1
df["Real mortgages interest rate"] = ((1+df["Interest rate"])/(1+df["General inflation"])) -1

df['$g_{I_h}$'] = df["Residential Investment"].pct_change()

    
fig, ax = plt.subplots(figsize=(19.2,10.8))

df[['Real mortgages interest rate', "Own interest rate", '$g_{I_h}$']].plot(ax=ax, lw=3)

ax.tick_params(axis="both", which="major", labelsize=15)
sns.despine()
salvar_grafico("TxPropria_Investo") 
plt.close('all')
#+END_SRC

#+RESULTS:
[[file:./figs/TxPropria_Investo.png]]

*** textcite:yeo_new_2000 transformation

#+BEGIN_SRC python :results graphics file :file ./figs/YeoJohnson_All.png
df = pd.read_csv("./data/Data_yeojohnson.csv", index_col=[0], parse_dates=True)

fig, ax = plt.subplots(figsize=(19.2, 10.8), sharey=True)

df[["Interest rate", "Inflation", "gIh", "Own Interest rate"]].plot(
    ax=ax,
    subplots=True,
    layout=(2, 2),
    # subplots=False,
    lw=3,
)
ax.legend(fontsize=14)
ax.tick_params(axis="both", which="major", labelsize=15)
plt.tight_layout()
sns.despine()

salvar_grafico("YeoJohnson_All")
plt.close("all")
#+END_SRC

#+RESULTS:
[[file:./figs/YeoJohnson_All.png]]

*** Construction 
**** Download
#+begin_src shell 
cd /HDD/PhD/Articles/VECM/data/

wget -N https://www.census.gov/construction/nrc/xls/avg_authtostart_cust.xls
mv avg_authtostart_cust.xls construcao_autorizacao.xls

wget -N https://www.census.gov/construction/nrc/xls/avg_starttocomp_cust.xls
mv avg_starttocomp_cust.xls construcao_tempo.xls
cd /HDD/PhD/Articles/VECM/
#+end_src

#+RESULTS:

**** Plot
#+BEGIN_SRC python :results graphics file :file ./figs/Meses_contrucao.png
df_autorizacao = pd.read_excel(
    "./data/construcao_autorizacao.xls", skiprows=11, index_col=[0], parse_dates=True
)
df_autorizacao.index.name = "Ano"
df_autorizacao.columns = [
    "Total",
    "Venda",
    "Contratado",
    "Proprietário",
    "Total (2 ou mais unidade)",
    "2 a 4",
    "5 a 9",
    "10 a 19",
    "20 ou mais",
]
df_autorizacao = df_autorizacao.apply(pd.to_numeric, errors="coerce")
numero_linhas = int((dt(2018, 1, 1) - dt(1976, 1, 1)).days / 365.25 + 1)
df_autorizacao = df_autorizacao.iloc[:numero_linhas, :]

df_start = pd.read_excel(
    "./data/construction.xls", skiprows=11, index_col=[0], parse_dates=True
)
df_start.index.name = "Ano"
df_start.columns = [
    "Total",
    "Venda",
    "Contratado",
    "Proprietário",
    "Total (2 ou mais unidade)",
    "2 a 4",
    "5 a 9",
    "10 a 19",
    "20 ou mais",
]
df_start = df_start.apply(pd.to_numeric, errors="coerce")
numero_linhas = int((dt(2018, 1, 1) - dt(1971, 1, 1)).days / 365.25 + 1)
df_start = df_start.iloc[:numero_linhas, :]
df = df_autorizacao + df_start
df = df.dropna()


fig, ax = plt.subplots(figsize=(19.2, 10.8))

sns.kdeplot(df["Total"], shade=True, color="darkred", ax=ax, label="Mean")
sns.kdeplot(df["Venda"], shade=True, color="darkgreen", ax=ax, label="For Sale")
sns.kdeplot(df["Contratado"], shade=True, color="orange", ax=ax, label="By contract")
sns.kdeplot(df["Proprietário"], shade=True, color="purple", ax=ax, label="By the owner")

# ax.xaxis.set_ticks(np.arange(0, 16, 3))
loc = plticker.MultipleLocator(base=3.0)  # this locator puts ticks at regular intervals
ax.xaxis.set_major_locator(loc)


ax.tick_params(axis="both", which="major", labelsize=15)
ax.set_xlabel("Months")
ax.set_ylabel("Probability density")

# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
ax.legend(fontsize=14)

ax.tick_params(axis="both", which="major", labelsize=15)
sns.despine()
plt.tight_layout()
salvar_grafico("Meses_construcao")
plt.close("all")
#+END_SRC

#+RESULTS:
[[file:./figs/Meses_contrucao.png]]

*** Cycles

#+BEGIN_SRC python :results graphics file :file ./figs/Ciclo_Ih_u.png
start = dt(1951, 12, 1)
end = dt(2019, 1, 1)
df = web.DataReader(
    [
        'GDP',
        'PRFI',
        'PNFI',
        'TCU',
        'PCDG',
    ], 
    'fred', 
    start, end
)

df.columns = [
    "GDP",
    "Residential investment",
    "Non-residential investment",
    "Capacity utilization",
    "Duráveis"
]

df['Capacity utilization'] = df['Capacity utilization']/100
df['Ih/GDP'] = df['Residential investment']/df['GDP']
df['If/GDP'] = df['Non-residential investment']/df['GDP']
df['Duráveis/GDP'] = df['Duráveis']/df['GDP']
df['Ano'] = df.index.year
df = df.resample('Q').last()
df['gY'] = df['GDP'].pct_change(4)

df.index.name = ''
df = df.dropna()

sns.set_context('talk')
fig, ax = plt.subplots(2,
                       3,
                       sharex=True,
                       sharey=True,
                       squeeze=False,
                       figsize=(19.2, 10.8))

sns.scatterplot(y='Ih/GDP',
                x='Capacity utilization',
                data=df["1970-12":"1975-01"],
                ax=ax[0, 0],
                size='Ano',
                sizes=(5, 300),
                color='black',
                legend=False)
sns.lineplot(y='Ih/GDP',
             x='Capacity utilization',
             data=df["1970-12":"1975-01"],
             ax=ax[0, 0],
             sort=False,
             color='black',
             lw=4,
            )
ax[0, 0].set_title("1970 (IV) - 1975 (I)", fontsize=18)

sns.scatterplot(y='Ih/GDP',
                x='Capacity utilization',
                data=df["1975-01":"1980-10"],
                ax=ax[0, 1],
                size='Ano',
                sizes=(5, 300),
                color='black',
                legend=False)
sns.lineplot(y='Ih/GDP',
             x='Capacity utilization',
             data=df["1975-01":"1980-10"],
             ax=ax[0, 1],
             sort=False,
             color='black',
             lw=4,)
ax[0, 1].set_title("1975 (I) - 1980 (III)", fontsize=18)

sns.scatterplot(y='Ih/GDP',
                x='Capacity utilization',
                data=df["1980-10":"1982-12"],
                ax=ax[0, 2],
                size='Ano',
                sizes=(5, 300),
                color='black',
                legend=False)
sns.lineplot(y='Ih/GDP',
             x='Capacity utilization',
             data=df["1980-10":"1982-12"],
             ax=ax[0, 2],
             sort=False,
             color='black',
             lw=4,)
ax[0, 2].set_title("1980 (III) - 1982 (IV)", fontsize=18)

sns.scatterplot(y='Ih/GDP',
                x='Capacity utilization',
                data=df["1982-12":"1991-01"],
                ax=ax[1, 0],
                size='Ano',
                sizes=(5, 300),
                color='black',
                legend=False)
sns.lineplot(y='Ih/GDP',
             x='Capacity utilization',
             data=df["1982-12":"1991-01"],
             ax=ax[1, 0],
             sort=False,
             color='black',
             lw=4,)
ax[1, 0].set_title("1982 (IV) - 1991 (I)")

sns.scatterplot(y='Ih/GDP',
                x='Capacity utilization',
                data=df["1991-01":"2001-12"],
                ax=ax[1, 1],
                size='Ano',
                sizes=(5, 300),
                color='black',
                legend=False)
sns.lineplot(y='Ih/GDP',
             x='Capacity utilization',
             data=df["1991-01":"2001-12"],
             ax=ax[1, 1],
             sort=False,
             color='black',
             lw=4,)
ax[1, 1].set_title("1991 (I) - 2001 (IV)", fontsize=18)

sns.scatterplot(y='Ih/GDP',
                x='Capacity utilization',
                data=df["2001-12":"2009-07"],
                ax=ax[1, 2],
                size='Ano',
                sizes=(5, 300),
                color='black',
                legend=False)
sns.lineplot(y='Ih/GDP',
             x='Capacity utilization',
             data=df["2001-12":"2009-07"],
             ax=ax[1, 2],
             sort=False,
             color='black',
             lw=4,)
ax[1, 2].set_title("2001 (IV) - 2009 (II)", fontsize=18)

sns.despine()
ax[0, 0].set_ylabel("")
ax[1, 0].set_xlabel('')
ax[1, 0].set_ylabel("")
ax[1, 1].set_xlabel('')
ax[1, 2].set_xlabel('')

fig.tight_layout(rect=[0, 0.03, 1, 0.90])
fig.text(0.5,
         0.03,
         'Capacity utilization (Total industry)',
         ha='center',
         fontsize=20)
fig.text(-0.01,
         0.5,
         'Residential investment/GDP',
         va='center',
         rotation='vertical',
         fontsize=20)
plt.suptitle(
    "(Markers sizes increases over time)"
)

salvar_grafico(file_name="Ciclo_Ih_u")
plt.close('all')
#+END_SRC

#+RESULTS:
[[file:./figs/Ciclo_Ih_u.png]]


** Model related 
#+BEGIN_SRC python
from statsmodels.tsa.vector_ar.var_model import VAR
from statsmodels.tsa.api import SVAR
from statsmodels.tsa.vector_ar.vecm import coint_johansen, CointRankResults, VECM, select_coint_rank

from statsmodels.stats.diagnostic import acorr_breusch_godfrey, acorr_ljungbox, het_arch, het_breuschpagan, het_white
from statsmodels.tsa.stattools import adfuller, kpss, grangercausalitytests, q_stat, coint
from arch.unitroot import PhillipsPerron, ZivotAndrews, DFGLS, KPSS, ADF

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf


import pandas_datareader.data as web
from scipy.stats import yeojohnson

start = dt(1987, 1, 1)
end = dt(2019, 7, 1)
#+END_SRC

#+RESULTS:
:results:
:end:

** Loading data

#+BEGIN_SRC python
df = web.DataReader(
    [
        "PRFI",
        "CSUSHPISA",
        "MORTGAGE30US",
    ], 
    'fred', 
    start, 
    end
)

df.columns = [
    "Residential Investment", 
    "House Prices", 
    "Interest rate",
]
df.index.name = ""

df['Interest rate'] = df['Interest rate'].divide(100)
df = df.resample('M').last()
df['House Prices'] = df['House Prices']/df['House Prices'][0]
df = df.resample('Q').last()

df["Inflation"] = df["House Prices"].pct_change() # Warning: 4
df['gIh'] = df["Residential Investment"].pct_change() # Warning: 4
df["Own Interest rate"] = ((1+df["Interest rate"])/(1+df["Inflation"])) -1

df['Own Interest rate'], *_ = yeojohnson(df['Own Interest rate'])
#df['Inflation'], *_ = yeojohnson(df['Inflation'])
df['gIh'], *_ = yeojohnson(df['gIh'])

df[["Inflation", "gIh", "Own Interest rate", "Interest rate"]].to_csv("./data/Complete_Data")

df["Crisis"] = [0 for i in range(len(df["gIh"]))]
for i in range(len(df["Crisis"])):
    if df.index[i] > dt(2007,12,1) and df.index[i] < dt(2009,7,1):
        df["Crisis"][i] = 1

df = df[["Interest rate", "Inflation", "gIh", "Crisis", "Own Interest rate"]]

df["d_Own Interest rate"] = df["Own Interest rate"].diff()
df["d_gIh"] = df["gIh"].diff()
df["d_Inflation"] = df["Inflation"].diff()
df["d_Interest rate"] = df['Interest rate'].diff()
df = df.dropna()
#+END_SRC

#+RESULTS:
:results:
/home/gpetrini/.local/lib/python3.8/site-packages/scipy/stats/morestats.py:1371: RuntimeWarning: invalid value encountered in greater_equal
  pos = x >= 0  # binary mask
/tmp/babel-lZ51sA/python-78e8Qn:37: SettingWithCopyWarning:
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df["Crisis"][i] = 1
:end:

** Functions
*** Unit root test
#+BEGIN_SRC python
def testes_raiz(df=df["gIh"], original_trend='c', diff_trend='c'):
    """
    serie: Nome da coluna do df
    orignal_trend: 'c', 'ct', 'ctt'
    diff_trend: 'c', 'ct', 'ctt'
    
    Plota série o original e em diferenta e retorna testes de raíz unitária
    """
    fig, ax = plt.subplots(1,2)

    df.plot(ax=ax[0], title='Original series')
    df.diff().plot(ax=ax[1], title='First differences')

    plt.tight_layout()
    sns.despine()
    plt.close('all')
    
    fig, ax = plt.subplots(2,2)
    
    plot_acf(df, ax=ax[0,0], title='ACF: serie original') 
    plot_pacf(df, ax=ax[0,1], title='PACF: serie original')
    
    plot_acf(df.diff().dropna(), ax=ax[1,0], title='ACF: serie em diferença') 
    plot_pacf(df.diff().dropna(), ax=ax[1,1], title='PACF: serie em diferença')
    
    plt.tight_layout()
    sns.despine() 
    plt.close('all')

    
    # Zivot Andrews
    print('\nZIVOT ANDREWS level series')
    print(ZivotAndrews(df, trend = original_trend).summary(),"\n")
    print('\nZIVOT ANDREWS First differences')
    print(ZivotAndrews(df.diff().dropna(), trend = diff_trend).summary(),"\n")
    
    print('\nADF level series')
    print(ADF(df, trend=original_trend).summary(),"\n")
    print('\nADF First differences')
    print(ADF(df.diff().dropna(), trend=diff_trend).summary(),"\n")
    
    print('\nDFGLS level series')
    print(DFGLS(df, trend=original_trend).summary(),"\n")
    print('\nDFGLS First differences')
    print(DFGLS(df.diff().dropna(), trend=diff_trend).summary(),"\n")
    
    print('\nKPSS em nível')
    print(KPSS(df, trend = original_trend).summary(),"\n")
    print('\nKPSS em primeira diferença')
    print(KPSS(df.diff().dropna(), trend = diff_trend).summary(),"\n")
    
    print('\nPhillips Perron em nível')
    print(PhillipsPerron(df, trend=original_trend).summary(),"\n")
    print('\nPhillips Perron em primeira diferença')
    print(PhillipsPerron(df.diff().dropna(), trend=diff_trend).summary(),"\n")
#+END_SRC

#+RESULTS:
:results:
:end:


*** Engel-Granger and Johansen conintegration test


#+BEGIN_SRC python
# Teste de cointegração

def cointegracao(ts0, ts1, signif = 0.05, lag=1):
  trends = ['nc', 'c', 'ct', 'ctt']
  for trend in trends:
    print(f"\nTestando para lag = {lag} e trend = {trend}")
    result = coint(ts0, ts1, trend = trend, maxlag=lag)
    print('Null Hypothesis: there is NO cointegration')
    print('Alternative Hypothesis: there IS cointegration')
    print('t Statistic: %f' % result[0])
    print('p-value: %f' % result[1])
    if result[1] < signif:
      print('CONCLUSION: REJECT null Hypothesis: there IS cointegration\n')
    else:
      print('CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration\n')
    
def testes_coint(series, maxlag=6, signif = 0.05,):
    for i in range(1, maxlag):
        print(50*'=')
        cointegracao(
            ts0=series.iloc[:, 0],
            ts1=series.iloc[:, 1:],
            signif=signif,
            lag=i
        )
        print("\nTESTE DE JOHANSEN\n")
        print("Teste SEM constante")
        result = select_coint_rank(endog=series, k_ar_diff=i, det_order=-1, signif=signif) ## Warning: 1
        print(result.summary())
        print(f'Para lag = {i} e significância = {signif*100}%, Rank = {result.rank}')
        print("\nTeste COM constante\n")
        result = select_coint_rank(endog=series, k_ar_diff=i, det_order=0, signif=signif) ## Warning: 1
        print(result.summary())
        print(f'Para lag = {i} e significância = {signif*100}%, Rank = {result.rank}')
        print("\nTeste COM constante E tendência\n")
        result = select_coint_rank(endog=series, k_ar_diff=i, det_order=1, signif=signif) ## Warning: 1
        print(result.summary())
        print(f'Para lag = {i} e significância = {signif*100}%, Rank = {result.rank}')
        print(10*'=')
#+END_SRC

#+RESULTS:
:results:
:end:

*** Residuals analysis: Ljung-Box and Box-Pierce

#+BEGIN_SRC python
### Resíduos

def LjungBox_Pierce(resid, signif = 0.05, boxpierce = False, k = 4):
  """
  resid = residuals df
  signif = signif. level
  """
  var = len(resid.columns)
  print("H0: autocorrelations up to lag k equal zero")
  print('H1: autocorrelations up to lag k not zero')
  print("Box-Pierce: ", boxpierce)
  
  for i in range(var):
    print("Testing for ", resid.columns[i].upper(), ". Considering a significance level of",  signif*100,"%")
    result = acorr_ljungbox(x = resid.iloc[:,i-1], lags = k, boxpierce = boxpierce)[i-1]
    conclusion = result < signif
    for j in range(k):
      print(f'p-value = {result[j]}')
      print("Reject H0 on lag " ,j+1,"? ", conclusion[j], "\n")
    print("\n")
    
def ARCH_LM(resid, signif = 0.05, autolag = 'bic'):
  """
  df = residuals df
  signif = signif. level
  """
  var = len(resid.columns)
  print("H0: Residuals are homoscedastic")
  print('H1: Residuals are heteroskedastic')
  
  for i in range(var):
    print("Testing for ", resid.columns[i].upper())
    result = het_arch(resid = resid.iloc[:,i], autolag = autolag)
    print('LM statistic: ', result[0])
    print('LM p-value: ', result[1])
    print("Reject H0? ", result[1] < signif)
    print('F statistic: ', result[2])
    print('F p-value: ', result[3])
    print("Reject H0? ", result[3] < signif)
    print('\n')
    

def analise_residuos(results, nmax=15):
    
    residuals = pd.DataFrame(results.resid, columns = results.names)
    
    residuals.plot()
    sns.despine()
    
    plt.close('all')
    
    for serie in residuals.columns:
        sns.set_context('talk')
        fig, ax = plt.subplots(1,2, figsize=(10,8))

        plot_acf(residuals[serie], ax=ax[0], title=f'ACF Resíduo de {serie}', zero=False) 
        plot_pacf(residuals[serie], ax=ax[1], title=f'PACF Resíduo de {serie}', zero=False)
        
        plt.tight_layout()
        sns.despine() 
        
        plt.close('all')

    print('AUTOCORRELAÇÃO RESIDUAL: PORTMANTEAU\n')
    print(results.test_whiteness(nlags=nmax).summary())
    print('\nAUTOCORRELAÇÃO RESIDUAL: PORTMANTEAU AJUSTADO\n')
    print(results.test_whiteness(nlags=nmax, adjusted=True).summary())
    print('\nLJUNGBOX\n')
    LjungBox_Pierce(residuals, k = 12, boxpierce=False)
    print('\nBOXPIERCE\n')
    LjungBox_Pierce(residuals, k = 12, boxpierce=True)
    print('\nNORMALIDADE\n')
    print(results.test_normality().summary())
    print('\nHOMOCEDASTICIDADE\n')
    ARCH_LM(residuals)
    
    return residuals
results = []
def plot_lags(results = results, trimestres=[2, 5]):
    series = results.names
    sns.set_context('talk')
    fig, ax = plt.subplots(len(trimestres),2, figsize = (16,10))
    
    for i in range(len(trimestres)):
        sns.regplot(y = df[series[0]], x = df[series[1]].shift(-trimestres[i]), color = 'black', ax = ax[i,0], order = 2)
        ax[i,0].set_xlabel(f'{series[1]} lagged in {trimestres[i]} quarters')

        sns.regplot(x = df[series[0]].shift(-trimestres[i]), y = df[series[1]], color = 'black', ax = ax[i,1], order = 2)
        ax[i,1].set_xlabel(f'{series[0]} lagged in {trimestres[i]} quarters')
        
    plt.tight_layout()
    plt.close('all')
    
    return fig
#+END_SRC

#+RESULTS:
:results:
:end:


*** FEVD for VECM

#+BEGIN_SRC python
from statsmodels.compat.python import lrange, iteritems
from statsmodels.tsa.vector_ar import output, plotting, util


def fmse(self, steps):
    r"""
    Compute theoretical forecast error variance matrices

    Parameters
    ----------
    steps : int
        Number of steps ahead

    Notes
    -----
    .. math:: \mathrm{MSE}(h) = \sum_{i=0}^{h-1} \Phi \Sigma_u \Phi^T

    Returns
    -------
    forc_covs : ndarray (steps x neqs x neqs)
    """
    ma_coefs = self.ma_rep(steps)

    k = len(self.sigma_u)
    forc_covs = np.zeros((steps, k, k))

    prior = np.zeros((k, k))
    for h in range(steps):
        # Sigma(h) = Sigma(h-1) + Phi Sig_u Phi'
        phi = ma_coefs[h]
        var = phi @ self.sigma_u @ phi.T
        forc_covs[h] = prior = prior + var

    return forc_covs


class FEVD(object):
    """
    Compute and plot Forecast error variance decomposition and asymptotic
    standard errors
    """

    def __init__(self, model, P=None, periods=None):

        self.periods = periods

        self.model = model
        self.neqs = model.neqs
        self.names = model.model.endog_names

        self.irfobj = model.irf(periods=periods)
        self.orth_irfs = self.irfobj.orth_irfs

        # cumulative impulse responses
        irfs = (self.orth_irfs[:periods] ** 2).cumsum(axis=0)

        rng = lrange(self.neqs)
        mse = fmse(self.model, periods)[:, rng, rng]

        # lag x equation x component
        fevd = np.empty_like(irfs)

        for i in range(periods):
            fevd[i] = (irfs[i].T / mse[i]).T

        # switch to equation x lag x component
        self.decomp = fevd.swapaxes(0, 1)

    def summary(self):
        buf = StringIO()

        rng = lrange(self.periods)
        for i in range(self.neqs):
            ppm = output.pprint_matrix(self.decomp[i], rng, self.names)

            buf.write("FEVD for %s\n" % self.names[i])
            buf.write(ppm + "\n")

        print(buf.getvalue())

    def plot(self, periods=None, figsize=(16, 5), **plot_kwds):
        """Plot graphical display of FEVD

        Parameters
        ----------
        periods : int, default None
            Defaults to number originally specified. Can be at most that number
        """
        import matplotlib.pyplot as plt

        k = self.neqs
        periods = periods or self.periods

        fig, axes = plt.subplots(nrows=k, figsize=figsize)
        fig, axes = plt.subplots(1, 2, figsize=figsize, sharey=True)

        # fig.suptitle('Forecast error variance decomposition (FEVD)')

        colors = ["black", "lightgray"]
        ticks = np.arange(periods)

        limits = self.decomp.cumsum(2)

        for i in range(k):
            ax = axes[i]

            this_limits = limits[i].T

            handles = []

            for j in range(k):
                lower = this_limits[j - 1] if j > 0 else 0
                upper = this_limits[j]
                handle = ax.bar(
                    ticks,
                    upper - lower,
                    bottom=lower,
                    color=colors[j],
                    label=self.names[j],
                    ,**plot_kwds
                )

                handles.append(handle)
            ax.axhline(y=0.5, color="red", ls="--", lw=3)

            ax.set_title(self.names[i])

        # just use the last axis to get handles for plotting
        handles, labels = ax.get_legend_handles_labels()
        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))
        # fig.legend(handles, labels, loc="lower right")
        # plotting.adjust_subplots(right=0.85)
        sns.despine()
        return fig
#+END_SRC

#+RESULTS:
:results:
:end:

*** Structural break test

#+begin_src ess-r :eval no :tangle ./code/strucchange.R
library(strucchange)
library(urca)
library(dplyr)

df <- read.csv(
  "./data/Complete_Data.csv",
  encoding="UTF-8", 
  stringsAsFactors=FALSE
  )
df <- ts(data = df, start = c(1987,01), frequency = 4)
df <- zoo::na.locf0(df)
colnames(df) <- c("X", "Infla", "gIh", "Own", "Interest rate")

## Taxa de crescimento do Residential investment


result = breakpoints(gIh~1, data=df)
result$breakpoints %>% unique() %>% na.omit() %>% c() -> breaks

for(i in breaks){
  print(paste0("Testando para i = ", index(df)[i]))
  strucchange::sctest(gIh~1, data=df, point=i, type="Chow") %>% print()
}


## Own Interest rate


result = breakpoints(Own~1, data=df)
result$breakpoints %>% unique() %>% na.omit() %>% c() -> breaks

for(i in breaks){
  print(paste0("Testando para i = ", index(df)[i]))
  strucchange::sctest(Own~1, data=df, point=i, type="Chow") %>% print()
}


## Interest rate


result = breakpoints(Interest rate~1, data=df)
result$breakpoints %>% unique() %>% na.omit() %>% c() -> breaks

for(i in breaks){
  print(paste0("Testando para i = ", index(df)[i]))
  strucchange::sctest(Interest rate~1, data=df, point=i, type="Chow") %>% print()
}


## Inflation


result = breakpoints(Infla~1, data=df)
result$breakpoints %>% unique() %>% na.omit() %>% c() -> breaks

for(i in breaks){
  print(paste0("Testando para i = ", index(df)[i]))
  strucchange::sctest(Infla~1, data=df, point=i, type="Chow") %>% print()
}
#+end_src

** Subseting

#+BEGIN_SRC python
df = df["1992-01-01":]
df[["Inflation", "gIh", "Own Interest rate", "Interest rate"]].to_csv(
    "../data/Data_yeojohnson.csv"
)


df[["Inflation", "gIh", "Own Interest rate", "Interest rate"]].to_csv(
    "../data/Data_yeojohnson_ascii.csv",
    encoding="ascii",
    header=[
        "infla",
        "gIh",
        "Own",
        "Interest rate",
    ],
)
df = df.dropna()
#+END_SRC

#+RESULTS:
:results:
:end:

** Unit root test 

*** Housing growth rate

#+BEGIN_SRC python
testes_raiz(df=df['gIh'])
#+END_SRC

#+RESULTS:
:results:
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "/tmp/pyOnlS37", line 3, in <module>
  File "/tmp/babel-lZ51sA/python-1Toc8Y", line 2, in <module>
    df[["Inflation", "gIh", "Own Interest rate", "Interest rate"]].to_csv(
  File "/home/gpetrini/.local/lib/python3.8/site-packages/pandas/core/generic.py", line 3170, in to_csv
    formatter.save()
  File "/home/gpetrini/.local/lib/python3.8/site-packages/pandas/io/formats/csvs.py", line 185, in save
    f, handles = get_handle(
  File "/home/gpetrini/.local/lib/python3.8/site-packages/pandas/io/common.py", line 493, in get_handle
    f = open(path_or_buf, mode, encoding=encoding, errors=errors, newline="")
FileNotFoundError: [Errno 2] Arquivo ou diretório inexistente: '../data/Data_yeojohnson.csv'
>>>
ZIVOT ANDREWS level series
        Zivot-Andrews Results
=====================================
Test Statistic                 -4.461
P-value                         0.132
Lags                               11
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ZIVOT ANDREWS First differences
        Zivot-Andrews Results
=====================================
Test Statistic                 -7.793
P-value                         0.000
Lags                                3
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ADF level series
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -3.342
P-value                         0.013
Lags                               11
-------------------------------------

Trend: Constant
Critical Values: -3.50 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


ADF First differences
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -7.204
P-value                         0.000
Lags                                3
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS level series
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -1.325
P-value                         0.177
Lags                                4
-------------------------------------

Trend: Constant
Critical Values: -2.75 (1%), -2.13 (5%), -1.82 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS First differences
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -0.967
P-value                         0.306
Lags                               10
-------------------------------------

Trend: Constant
Critical Values: -2.76 (1%), -2.14 (5%), -1.83 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


KPSS em nível
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.178
P-value                         0.315
Lags                                5
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


KPSS em primeira diferença
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.097
P-value                         0.601
Lags                               21
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


Phillips Perron em nível
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                 -6.136
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


Phillips Perron em primeira diferença
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                -20.273
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.
:end:

*** Own rate of interest

#+BEGIN_SRC python
testes_raiz(df['Own Interest rate'])
#+END_SRC

#+RESULTS:
:results:

ZIVOT ANDREWS level series
        Zivot-Andrews Results
=====================================
Test Statistic                 -4.218
P-value                         0.230
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ZIVOT ANDREWS First differences
        Zivot-Andrews Results
=====================================
Test Statistic                 -6.351
P-value                         0.000
Lags                                4
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ADF level series
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -2.320
P-value                         0.165
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


ADF First differences
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -5.101
P-value                         0.000
Lags                                4
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS level series
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -1.039
P-value                         0.277
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -2.74 (1%), -2.12 (5%), -1.81 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS First differences
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -3.775
P-value                         0.000
Lags                                3
-------------------------------------

Trend: Constant
Critical Values: -2.75 (1%), -2.13 (5%), -1.82 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


KPSS em nível
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.690
P-value                         0.014
Lags                                6
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


KPSS em primeira diferença
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.061
P-value                         0.811
Lags                                3
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


Phillips Perron em nível
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                 -2.415
P-value                         0.138
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


Phillips Perron em primeira diferença
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                -10.395
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.
:end:

*** Inflation

#+BEGIN_SRC python
testes_raiz(df['Inflation'])
#+END_SRC

#+RESULTS:
:results:

ZIVOT ANDREWS level series
        Zivot-Andrews Results
=====================================
Test Statistic                 -4.890
P-value                         0.041
Lags                                4
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ZIVOT ANDREWS First differences
        Zivot-Andrews Results
=====================================
Test Statistic                 -6.148
P-value                         0.001
Lags                                4
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ADF level series
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -2.674
P-value                         0.079
Lags                                4
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


ADF First differences
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -4.707
P-value                         0.000
Lags                                4
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS level series
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -2.533
P-value                         0.011
Lags                                4
-------------------------------------

Trend: Constant
Critical Values: -2.75 (1%), -2.13 (5%), -1.82 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS First differences
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -3.939
P-value                         0.000
Lags                                3
-------------------------------------

Trend: Constant
Critical Values: -2.75 (1%), -2.13 (5%), -1.82 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


KPSS em nível
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.148
P-value                         0.395
Lags                                5
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


KPSS em primeira diferença
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.059
P-value                         0.823
Lags                                6
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


Phillips Perron em nível
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                 -2.701
P-value                         0.074
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


Phillips Perron em primeira diferença
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                -11.338
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.
:end:

*** Mortgage interest rate

#+BEGIN_SRC python
testes_raiz(df['Interest rate'], original_trend='ct')
#+END_SRC

#+RESULTS:
:results:

ZIVOT ANDREWS level series
        Zivot-Andrews Results
=====================================
Test Statistic                 -4.494
P-value                         0.215
Lags                                0
-------------------------------------

Trend: Constant and Linear Time Trend
Critical Values: -5.58 (1%), -5.07 (5%), -4.83 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ZIVOT ANDREWS First differences
        Zivot-Andrews Results
=====================================
Test Statistic                 -8.144
P-value                         0.000
Lags                                1
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ADF level series
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -3.638
P-value                         0.027
Lags                                0
-------------------------------------

Trend: Constant and Linear Time Trend
Critical Values: -4.04 (1%), -3.45 (5%), -3.15 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


ADF First differences
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -8.050
P-value                         0.000
Lags                                1
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS level series
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -3.445
P-value                         0.009
Lags                                0
-------------------------------------

Trend: Constant and Linear Time Trend
Critical Values: -3.60 (1%), -3.02 (5%), -2.73 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS First differences
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -1.074
P-value                         0.264
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -2.76 (1%), -2.14 (5%), -1.83 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


KPSS em nível
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.081
P-value                         0.264
Lags                                5
-------------------------------------

Trend: Constant and Linear Time Trend
Critical Values: 0.22 (1%), 0.15 (5%), 0.12 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


KPSS em primeira diferença
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.034
P-value                         0.962
Lags                                3
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


Phillips Perron em nível
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                 -3.604
P-value                         0.030
Lags                               13
-------------------------------------

Trend: Constant and Linear Time Trend
Critical Values: -4.04 (1%), -3.45 (5%), -3.15 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


Phillips Perron em primeira diferença
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                -11.127
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.
:end:

** Cointegration

*** $g_{I_{h}}$ and own rate of interest




#+BEGIN_SRC python
print("VAR Order\n")

model = VAR(
    df[["gIh", 'Own Interest rate']])
print(model.select_order(maxlags=15, trend='ct').summary())

testes_coint(series=df[['gIh', 'Own Interest rate']], maxlag=9)
#+END_SRC

#+RESULTS:
:results:
VAR Order

 VAR Order Selection (* highlights the minimums)
==================================================
       AIC         BIC         FPE         HQIC
--------------------------------------------------
0       -14.83      -14.72   3.634e-07      -14.78
1       -16.33     -16.11*   8.093e-08      -16.24
2       -16.30      -15.98   8.333e-08      -16.17
3       -16.42      -15.99   7.381e-08      -16.25
4       -16.47      -15.93   7.073e-08      -16.25
5      -16.57*      -15.92  6.388e-08*     -16.31*
6       -16.50      -15.75   6.832e-08      -16.20
7       -16.46      -15.60   7.163e-08      -16.11
8       -16.40      -15.43   7.643e-08      -16.01
9       -16.40      -15.32   7.641e-08      -15.97
10      -16.34      -15.15   8.180e-08      -15.86
11      -16.33      -15.04   8.303e-08      -15.81
12      -16.55      -15.15   6.673e-08      -15.99
13      -16.49      -14.99   7.136e-08      -15.88
14      -16.48      -14.86   7.316e-08      -15.82
15      -16.43      -14.71   7.745e-08      -15.73
--------------------------------------------------
==================================================

Testando para lag = 1 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.167471
p-value: 0.016924
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 1 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -4.367300
p-value: 0.002006
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 1 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -9.116071
p-value: 0.000000
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 1 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -9.994341
p-value: 0.000000
CONCLUSION: REJECT null Hypothesis: there IS cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          13.16          12.32
  1   2          3.017          4.130
-------------------------------------
Para lag = 1 e significância = 5.0%, Rank = 1

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          23.59          15.49
  1   2          5.131          3.841
-------------------------------------
Para lag = 1 e significância = 5.0%, Rank = 2

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          48.49          18.40
  1   2          6.027          3.841
-------------------------------------
Para lag = 1 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 2 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.430520
p-value: 0.106307
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 2 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.822540
p-value: 0.158618
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 2 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -4.403550
p-value: 0.007793
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 2 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -9.994341
p-value: 0.000000
CONCLUSION: REJECT null Hypothesis: there IS cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          12.61          12.32
  1   2          3.016          4.130
-------------------------------------
Para lag = 2 e significância = 5.0%, Rank = 1

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          15.62          15.49
  1   2          4.537          3.841
-------------------------------------
Para lag = 2 e significância = 5.0%, Rank = 2

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          26.14          18.40
  1   2          6.671          3.841
-------------------------------------
Para lag = 2 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 3 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.829766
p-value: 0.042222
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 3 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.822540
p-value: 0.158618
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 3 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -4.403550
p-value: 0.007793
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 3 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -9.994341
p-value: 0.000000
CONCLUSION: REJECT null Hypothesis: there IS cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          17.19          12.32
  1   2          2.499          4.130
-------------------------------------
Para lag = 3 e significância = 5.0%, Rank = 1

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          20.97          15.49
  1   2          3.967          3.841
-------------------------------------
Para lag = 3 e significância = 5.0%, Rank = 2

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          33.40          18.40
  1   2          7.554          3.841
-------------------------------------
Para lag = 3 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 4 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.244003
p-value: 0.154161
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 4 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.166951
p-value: 0.441466
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 4 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.127798
p-value: 0.211884
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 4 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -9.994341
p-value: 0.000000
CONCLUSION: REJECT null Hypothesis: there IS cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          18.69          12.32
  1   2          2.377          4.130
-------------------------------------
Para lag = 4 e significância = 5.0%, Rank = 1

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          19.06          15.49
  1   2          3.744          3.841
-------------------------------------
Para lag = 4 e significância = 5.0%, Rank = 1

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          27.89          18.40
  1   2          13.25          3.841
-------------------------------------
Para lag = 4 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 5 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.244003
p-value: 0.154161
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 5 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.166951
p-value: 0.441466
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 5 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.127798
p-value: 0.211884
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 5 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -9.994341
p-value: 0.000000
CONCLUSION: REJECT null Hypothesis: there IS cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          15.46          12.32
  1   2          2.635          4.130
-------------------------------------
Para lag = 5 e significância = 5.0%, Rank = 1

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          14.70          15.49
-------------------------------------
Para lag = 5 e significância = 5.0%, Rank = 0

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          21.18          18.40
  1   2          9.592          3.841
-------------------------------------
Para lag = 5 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 6 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.244003
p-value: 0.154161
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 6 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.166951
p-value: 0.441466
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 6 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.214580
p-value: 0.672873
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 6 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -9.994341
p-value: 0.000000
CONCLUSION: REJECT null Hypothesis: there IS cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          13.55          12.32
  1   2          2.445          4.130
-------------------------------------
Para lag = 6 e significância = 5.0%, Rank = 1

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          11.87          15.49
-------------------------------------
Para lag = 6 e significância = 5.0%, Rank = 0

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          17.37          18.40
-------------------------------------
Para lag = 6 e significância = 5.0%, Rank = 0
==========
==================================================

Testando para lag = 7 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.244003
p-value: 0.154161
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 7 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.166951
p-value: 0.441466
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 7 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.127798
p-value: 0.211884
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 7 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.521249
p-value: 0.207330
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          15.33          12.32
  1   2          3.345          4.130
-------------------------------------
Para lag = 7 e significância = 5.0%, Rank = 1

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          13.86          15.49
-------------------------------------
Para lag = 7 e significância = 5.0%, Rank = 0

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          17.54          18.40
-------------------------------------
Para lag = 7 e significância = 5.0%, Rank = 0
==========
==================================================

Testando para lag = 8 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.244003
p-value: 0.154161
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 8 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.166951
p-value: 0.441466
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 8 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.127798
p-value: 0.211884
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 8 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.521249
p-value: 0.207330
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          18.19          12.32
  1   2          4.179          4.130
-------------------------------------
Para lag = 8 e significância = 5.0%, Rank = 2

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          14.36          15.49
-------------------------------------
Para lag = 8 e significância = 5.0%, Rank = 0

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          15.62          18.40
-------------------------------------
Para lag = 8 e significância = 5.0%, Rank = 0
==========
:end:

*** $g_{I_{h}}$ and inflation

#+BEGIN_SRC python
testes_coint(series=df[['gIh', 'Inflation']])
#+END_SRC

#+RESULTS:
:results:
==================================================

Testando para lag = 1 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -5.115974
p-value: 0.000011
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 1 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -5.072610
p-value: 0.000121
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 1 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -5.038917
p-value: 0.000738
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 1 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -5.207764
p-value: 0.001547
CONCLUSION: REJECT null Hypothesis: there IS cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          32.24          12.32
  1   2          4.396          4.130
-------------------------------------
Para lag = 1 e significância = 5.0%, Rank = 2

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          33.71          15.49
  1   2          6.001          3.841
-------------------------------------
Para lag = 1 e significância = 5.0%, Rank = 2

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          33.37          18.40
  1   2          6.050          3.841
-------------------------------------
Para lag = 1 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 2 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.439817
p-value: 0.007431
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 2 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.400061
p-value: 0.042344
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 2 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.374609
p-value: 0.130583
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 2 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.446565
p-value: 0.237158
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          24.97          12.32
  1   2          5.167          4.130
-------------------------------------
Para lag = 2 e significância = 5.0%, Rank = 2

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          26.77          15.49
  1   2          7.049          3.841
-------------------------------------
Para lag = 2 e significância = 5.0%, Rank = 2

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          26.28          18.40
  1   2          7.104          3.841
-------------------------------------
Para lag = 2 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 3 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.439817
p-value: 0.007431
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 3 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.400061
p-value: 0.042344
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 3 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.374609
p-value: 0.130583
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 3 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -3.446565
p-value: 0.237158
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          29.91          12.32
  1   2          4.805          4.130
-------------------------------------
Para lag = 3 e significância = 5.0%, Rank = 2

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          31.65          15.49
  1   2          6.490          3.841
-------------------------------------
Para lag = 3 e significância = 5.0%, Rank = 2

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          30.64          18.40
  1   2          6.517          3.841
-------------------------------------
Para lag = 3 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 4 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.886233
p-value: 0.036542
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 4 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.834073
p-value: 0.155084
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 4 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.783921
p-value: 0.366704
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 4 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.818192
p-value: 0.561347
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          24.78          12.32
  1   2          8.450          4.130
-------------------------------------
Para lag = 4 e significância = 5.0%, Rank = 2

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          27.57          15.49
  1   2          11.36          3.841
-------------------------------------
Para lag = 4 e significância = 5.0%, Rank = 2

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          26.73          18.40
  1   2          11.41          3.841
-------------------------------------
Para lag = 4 e significância = 5.0%, Rank = 2
==========
==================================================

Testando para lag = 5 e trend = nc
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.886233
p-value: 0.036542
CONCLUSION: REJECT null Hypothesis: there IS cointegration


Testando para lag = 5 e trend = c
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.834073
p-value: 0.155084
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 5 e trend = ct
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.783921
p-value: 0.366704
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


Testando para lag = 5 e trend = ctt
Null Hypothesis: there is NO cointegration
Alternative Hypothesis: there IS cointegration
t Statistic: -2.818192
p-value: 0.561347
CONCLUSION: FAIL to reject Null Hypothesis: there is NO cointegration


TESTE DE JOHANSEN

Teste SEM constante
Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          19.02          12.32
  1   2          5.151          4.130
-------------------------------------
Para lag = 5 e significância = 5.0%, Rank = 2

Teste COM constante

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          20.94          15.49
  1   2          7.216          3.841
-------------------------------------
Para lag = 5 e significância = 5.0%, Rank = 2

Teste COM constante E tendência

Johansen cointegration test using trace test statistic with 5% significance level
=====================================
r_0 r_1 test statistic critical value
-------------------------------------
  0   2          19.93          18.40
  1   2          7.249          3.841
-------------------------------------
Para lag = 5 e significância = 5.0%, Rank = 2
==========
:end:

** VECM Estimation

VECM: $g_Z$, Inflation e Interest rate exogenous

*** Model order selection

#+BEGIN_SRC python :results latex table
from statsmodels.tsa.vector_ar.vecm import select_order

#det = 'cili'
#det = 'coli'
#det = 'colo'
det = 'cilo'
#det = 'ci'
#det = 'nc'
#det= 'co'

order_vec = select_order(
    df[[
        #"Inflation", 
        "Own Interest rate", 
        "gIh"
    ]], 
    #exog=df[["Interest rate"]],
    #seasons=4,
    maxlags=15, deterministic=det)
order_sel = order_vec.summary().as_latex_tabular(tile = "Selação ordem do VECM") 
with open('./tabs/VECM_lag_order.tex','w') as fh:
    fh.write(order_sel)

print(order_sel)
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{center}
\begin{tabular}{lcccc}
\toprule
            & \textbf{AIC} & \textbf{BIC} & \textbf{FPE} & \textbf{HQIC}  \\
\midrule
\textbf{0}  &      -16.27  &     -16.00*  &   8.622e-08  &       -16.16   \\
\textbf{1}  &      -16.24  &      -15.86  &   8.864e-08  &       -16.09   \\
\textbf{2}  &      -16.36  &      -15.87  &   7.878e-08  &       -16.16   \\
\textbf{3}  &      -16.40  &      -15.80  &   7.558e-08  &       -16.16   \\
\textbf{4}  &     -16.50*  &      -15.80  &  6.827e-08*  &      -16.22*   \\
\textbf{5}  &      -16.44  &      -15.63  &   7.305e-08  &       -16.11   \\
\textbf{6}  &      -16.39  &      -15.47  &   7.682e-08  &       -16.02   \\
\textbf{7}  &      -16.33  &      -15.30  &   8.192e-08  &       -15.91   \\
\textbf{8}  &      -16.33  &      -15.20  &   8.193e-08  &       -15.87   \\
\textbf{9}  &      -16.27  &      -15.02  &   8.777e-08  &       -15.77   \\
\textbf{10} &      -16.26  &      -14.90  &   8.947e-08  &       -15.71   \\
\textbf{11} &      -16.49  &      -15.03  &   7.113e-08  &       -15.90   \\
\textbf{12} &      -16.43  &      -14.86  &   7.637e-08  &       -15.80   \\
\textbf{13} &      -16.41  &      -14.73  &   7.847e-08  &       -15.73   \\
\textbf{14} &      -16.37  &      -14.58  &   8.312e-08  &       -15.64   \\
\textbf{15} &      -16.32  &      -14.42  &   8.854e-08  &       -15.55   \\
\bottomrule
\end{tabular}
%\caption{VECM Order Selection (* highlights the minimums)}
\end{center}
#+end_export

*** Estimation

#+BEGIN_SRC python :results latex table
model = VECM(
    endog = df[[
        #"Inflation", 
        "Own Interest rate", 
        "gIh"
    ]], 
    #exog=df[["Interest rate"]],
    #k_ar_diff=0,
    #k_ar_diff=1,
    #k_ar_diff=2,
    #k_ar_diff=3,
    k_ar_diff=4,
    #k_ar_diff=5,
    #k_ar_diff=6,
    #k_ar_diff=7,
    #k_ar_diff=8,
    deterministic=det, 
    #seasons=4,
)
results = model.fit()
adjust = results.summary().as_latex() 
with open('./tabs/VECM_ajuste.tex','w') as fh:
    fh.write(adjust)

print(adjust)
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{center}
\begin{tabular}{lcccccc}
\toprule
                              & \textbf{coef} & \textbf{std err} & \textbf{z} & \textbf{P$> |$z$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{lin\_trend}           &   -9.993e-06  &     4.14e-05     &    -0.241  &         0.809        &    -9.11e-05    &     7.11e-05     \\
\textbf{L1.Own Interest rate} &       0.0323  &        0.111     &     0.291  &         0.771        &       -0.185    &        0.249     \\
\textbf{L1.gIh}               &       0.0654  &        0.082     &     0.797  &         0.426        &       -0.095    &        0.226     \\
\textbf{L2.Own Interest rate} &      -0.0076  &        0.109     &    -0.070  &         0.944        &       -0.222    &        0.207     \\
\textbf{L2.gIh}               &       0.1070  &        0.081     &     1.322  &         0.186        &       -0.052    &        0.266     \\
\textbf{L3.Own Interest rate} &       0.0809  &        0.118     &     0.685  &         0.493        &       -0.151    &        0.312     \\
\textbf{L3.gIh}               &       0.1072  &        0.069     &     1.561  &         0.119        &       -0.027    &        0.242     \\
\textbf{L4.Own Interest rate} &       0.2705  &        0.119     &     2.272  &         0.023        &        0.037    &        0.504     \\
                              & \textbf{coef} & \textbf{std err} & \textbf{z} & \textbf{P$> |$z$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{lin\_trend}           &      -0.0003  &     6.51e-05     &    -3.901  &         0.000        &       -0.000    &       -0.000     \\
\textbf{L1.Own Interest rate} &      -0.1860  &        0.174     &    -1.068  &         0.285        &       -0.527    &        0.155     \\
\textbf{L1.gIh}               &      -0.4241  &        0.129     &    -3.285  &         0.001        &       -0.677    &       -0.171     \\
\textbf{L2.Own Interest rate} &      -1.0124  &        0.172     &    -5.890  &         0.000        &       -1.349    &       -0.675     \\
\textbf{L2.gIh}               &      -0.4640  &        0.127     &    -3.645  &         0.000        &       -0.713    &       -0.214     \\
\textbf{L3.Own Interest rate} &      -0.6077  &        0.186     &    -3.271  &         0.001        &       -0.972    &       -0.244     \\
\textbf{L3.gIh}               &      -0.2088  &        0.108     &    -1.933  &         0.053        &       -0.421    &        0.003     \\
\textbf{L4.Own Interest rate} &      -0.5448  &        0.187     &    -2.909  &         0.004        &       -0.912    &       -0.178     \\
\textbf{L4.gIh}               &      -0.2526  &        0.084     &    -3.010  &         0.003        &       -0.417    &       -0.088     \\
             & \textbf{coef} & \textbf{std err} & \textbf{z} & \textbf{P$> |$z$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{ec1} &      -0.0121  &        0.068     &    -0.178  &         0.858        &       -0.145    &        0.121     \\
             & \textbf{coef} & \textbf{std err} & \textbf{z} & \textbf{P$> |$z$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{ec1} &      -0.4119  &        0.107     &    -3.864  &         0.000        &       -0.621    &       -0.203     \\
                & \textbf{coef} & \textbf{std err} & \textbf{z} & \textbf{P$> |$z$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{beta.1} &       1.0000  &            0     &         0  &         0.000        &        1.000    &        1.000     \\
\textbf{beta.2} &       1.3167  &        0.156     &     8.431  &         0.000        &        1.011    &        1.623     \\
\textbf{const}  &      -0.1127  &        0.009     &   -11.940  &         0.000        &       -0.131    &       -0.094     \\
\bottomrule
\end{tabular}
%\caption{Det. terms outside the coint. relation & lagged endog. parameters for equation Own Interest rate}
\end{center}
#+end_export

*** Impsulse respose

**** Orthoganalized

#+BEGIN_SRC python :results graphics file :file ./figs/Impulse_VECMOrth.png
p = results.irf(20).plot(orth=True)
p.suptitle("")
sns.despine()


p.savefig("./figs/Impulse_VECMOrth.png", dpi = 300, bbox_inches = 'tight',
    pad_inches = 0.0, transparent = False,)
plt.close('all')
#+END_SRC

#+RESULTS:
[[file:./figs/Impulse_VECMOrth.png]]

**** Non-Orthoganalized

#+BEGIN_SRC python :results graphics file :file ./figs/Impulse_VECM.png
p = results.irf(20).plot(orth=False)
p.suptitle("")
sns.despine()


p.savefig("./figs/Impulse_VECM.png", dpi = 300, bbox_inches = 'tight',
    pad_inches = 0.0, transparent = False,)
plt.close('all')
#+END_SRC

#+RESULTS:
[[file:./figs/Impulse_VECM.png]]

*** FEVD
**** Python version
#+BEGIN_SRC python :results graphics file :file ./figs/FEVD_VECMpython_TxPropria.png
fig = FEVD(results, periods=21).plot()
fig.savefig("./figs/FEVD_VECMpython_TxPropria.png", dpi = 300, bbox_inches = 'tight',
    pad_inches = 0.2, transparent = False,)
plt.close('all')
#+END_SRC

#+RESULTS:
[[file:./figs/FEVD_VECMpython_TxPropria.png]]
**** R version
#+begin_src ess-r :eval no
library(tsDyn)
library(readr)
df <- read.csv("../data/Data_yeojohnson.csv", encoding="UTF-8")
#df <- df[,c(4:7)]
names(df) <- c("Time","Infla", "gIh", "Own", "Interest rate")
df <- na.omit(df[,c("Time","Infla", "gIh", "Own", "Interest rate")])
df <- ts(data = df, start = c(1992,03), frequency = 4)
model <- tsDyn::VECM(data = df[,c("Own","gIh")], lag = 4, r = 1, estim = "ML", LRinclude="both", include="none")
fevd_gIh = data.frame(tsDyn::fevd(model, 20)$gIh)
fevd_tx = data.frame(tsDyn::fevd(model, 20)$Own)
#+end_src

*** Granger-Causality test 
#+BEGIN_SRC python
series = residuals.columns
print(results.test_granger_causality(causing=series[0], caused=series[1]).summary())
print(results.test_inst_causality(causing=series[0]).summary())
#+END_SRC

#+RESULTS:
:results:
:end:


*** Post estimation
#+BEGIN_SRC python
residuals = analise_residuos(results=results)
#+END_SRC

#+RESULTS:
:results:
AUTOCORRELAÇÃO RESIDUAL: PORTMANTEAU

Portmanteau-test for residual autocorrelation. H_0: residual autocorrelation up to lag 15 is zero. Conclusion: fail to reject H_0 at 5% significance level.
========================================
Test statistic Critical value p-value df
----------------------------------------
         50.47          58.12   0.174 42
----------------------------------------

AUTOCORRELAÇÃO RESIDUAL: PORTMANTEAU AJUSTADO

Adjusted Portmanteau-test for residual autocorrelation. H_0: residual autocorrelation up to lag 15 is zero. Conclusion: fail to reject H_0 at 5% significance level.
========================================
Test statistic Critical value p-value df
----------------------------------------
         55.49          58.12   0.079 42
----------------------------------------

LJUNGBOX

H0: autocorrelations up to lag k equal zero
H1: autocorrelations up to lag k not zero
Box-Pierce:  False
Testing for  OWN INTEREST RATE . Considering a significance level of 5.0 %
/home/gpetrini/.local/lib/python3.8/site-packages/statsmodels/stats/diagnostic.py:524: FutureWarning: The value returned will change to a single DataFrame after 0.12 is released.  Set return_df to True to use to return a DataFrame now.  Set return_df to False to silence this warning.
  warnings.warn(msg, FutureWarning)
p-value = 0.9221890789946033
Reject H0 on lag  1 ?  False

p-value = 0.9882661993852673
Reject H0 on lag  2 ?  False

p-value = 0.9401166590473613
Reject H0 on lag  3 ?  False

p-value = 0.8975741069713341
Reject H0 on lag  4 ?  False

p-value = 0.9556641515940801
Reject H0 on lag  5 ?  False

p-value = 0.9372408154573
Reject H0 on lag  6 ?  False

p-value = 0.9078848989066519
Reject H0 on lag  7 ?  False

p-value = 0.7049768031126116
Reject H0 on lag  8 ?  False

p-value = 0.6466808184117208
Reject H0 on lag  9 ?  False

p-value = 0.5325649743813294
Reject H0 on lag  10 ?  False

p-value = 0.5617077431441693
Reject H0 on lag  11 ?  False

p-value = 0.6374829192454776
Reject H0 on lag  12 ?  False



Testing for  GIH . Considering a significance level of 5.0 %
p-value = 0.2928438865892487
Reject H0 on lag  1 ?  False

p-value = 0.3214060364981588
Reject H0 on lag  2 ?  False

p-value = 0.35223359849202623
Reject H0 on lag  3 ?  False

p-value = 0.6968808413898132
Reject H0 on lag  4 ?  False

p-value = 2.7078322902468117
Reject H0 on lag  5 ?  False

p-value = 2.7291018355802854
Reject H0 on lag  6 ?  False

p-value = 2.757449261953701
Reject H0 on lag  7 ?  False

p-value = 4.228072172822588
Reject H0 on lag  8 ?  False

p-value = 4.3722293897598705
Reject H0 on lag  9 ?  False

p-value = 4.467213731646196
Reject H0 on lag  10 ?  False

p-value = 8.461592824979224
Reject H0 on lag  11 ?  False

p-value = 10.043381370583266
Reject H0 on lag  12 ?  False




BOXPIERCE

H0: autocorrelations up to lag k equal zero
H1: autocorrelations up to lag k not zero
Box-Pierce:  True
Testing for  OWN INTEREST RATE . Considering a significance level of 5.0 %
p-value = 0.9232842254033358
Reject H0 on lag  1 ?  False

p-value = 0.9886582805809287
Reject H0 on lag  2 ?  False

p-value = 0.9438947638006764
Reject H0 on lag  3 ?  False

p-value = 0.9063434757309058
Reject H0 on lag  4 ?  False

p-value = 0.9604769403779105
Reject H0 on lag  5 ?  False

p-value = 0.9459999009400404
Reject H0 on lag  6 ?  False

p-value = 0.9231691176443677
Reject H0 on lag  7 ?  False

p-value = 0.7536348535475705
Reject H0 on lag  8 ?  False

p-value = 0.70793304762609
Reject H0 on lag  9 ?  False

p-value = 0.6123508492313927
Reject H0 on lag  10 ?  False

p-value = 0.645134788175992
Reject H0 on lag  11 ?  False

p-value = 0.7169517982961326
Reject H0 on lag  12 ?  False



Testing for  GIH . Considering a significance level of 5.0 %
p-value = 0.2928438865892487
Reject H0 on lag  1 ?  False

p-value = 0.3214060364981588
Reject H0 on lag  2 ?  False

p-value = 0.35223359849202623
Reject H0 on lag  3 ?  False

p-value = 0.6968808413898132
Reject H0 on lag  4 ?  False

p-value = 2.7078322902468117
Reject H0 on lag  5 ?  False

p-value = 2.7291018355802854
Reject H0 on lag  6 ?  False

p-value = 2.757449261953701
Reject H0 on lag  7 ?  False

p-value = 4.228072172822588
Reject H0 on lag  8 ?  False

p-value = 4.3722293897598705
Reject H0 on lag  9 ?  False

p-value = 4.467213731646196
Reject H0 on lag  10 ?  False

p-value = 8.461592824979224
Reject H0 on lag  11 ?  False

p-value = 10.043381370583266
Reject H0 on lag  12 ?  False




NORMALIDADE

normality (skew and kurtosis) test. H_0: data generated by normally-distributed process. Conclusion: reject H_0 at 5% significance level.
========================================
Test statistic Critical value p-value df
----------------------------------------
         46.66          9.488   0.000  4
----------------------------------------

HOMOCEDASTICIDADE

H0: Residuals are homoscedastic
H1: Residuals are heteroskedastic
Testing for  OWN INTEREST RATE
/home/gpetrini/.local/lib/python3.8/site-packages/statsmodels/stats/diagnostic.py:622: FutureWarning: The default value of nlags is changing.  After 0.12, this value will become min(10, nobs//5). Directly setmaxlags or period to silence this warning.
  warnings.warn("The default value of nlags is changing.  After 0.12, "
/home/gpetrini/.local/lib/python3.8/site-packages/statsmodels/stats/diagnostic.py:645: FutureWarning: autolag is deprecated and will be removed after 0.12. Model selection before testing fails to control test size. Set autolag to False to silence this warning.
  warnings.warn("autolag is deprecated and will be removed after 0.12. "
LM statistic:  1.8119954250054855
LM p-value:  0.17826904516801384
Reject H0?  False
F statistic:  1.8086617320619
F p-value:  0.1816516384818212
Reject H0?  False


Testing for  GIH
LM statistic:  3.6552958325086884
LM p-value:  0.055891228580347334
Reject H0?  False
F statistic:  3.7155939419937525
F p-value:  0.0566879745640323
Reject H0?  False
:end:

**** Visual inspection

#+BEGIN_SRC python
series = results.names
for serie in series:
    sns.scatterplot(x = residuals[serie], y = residuals[serie]**2)
    plt.ylabel(f"{serie}^2")
    sns.despine()
    
    plt.close('all')
    sns.scatterplot(
    y = residuals[serie], 
    x = residuals[serie].shift(-1), 
    color = 'darkred' 
    )
    sns.despine()
    plt.xlabel(f"{serie}(-1)")
    
    plt.close('all')
#+END_SRC

#+RESULTS:
:results:
:end:
***** All residuals
#+BEGIN_SRC python :results graphics file :file ./figs/Residuals_4VECM.png
plt.tight_layout()
g.savefig("./figs/Residuals_4VECM.png", dpi = 300, bbox_inches = 'tight',
    pad_inches = 0.2, transparent = False,)
plt.close(g)
#+END_SRC

#+RESULTS:
[[file:./figs/Residuals_4VECM.png]]
***** Residuals vs Residuals
#+BEGIN_SRC python
series = results.names
ax = sns.jointplot(
    x = series[0], 
    y = series[1], 
    data = residuals, color = 'darkred', kind="reg", 
)
plt.close('all')
#+END_SRC

#+RESULTS:
:results:
:end:
***** Lags vs Lags
#+BEGIN_SRC python :results graphics file :file ./figs/VEC_Defasagens.png
fig = plot_lags(results=results, trimestres=[1,4])
fig.savefig("./figs/VEC_Defasagens.png", dpi = 300, bbox_inches = 'tight',
    pad_inches = 0.2, transparent = False,)
plt.close(fig)
#+END_SRC

#+RESULTS:
[[file:./figs/VEC_Defasagens.png]]

**** Residuals stationarity
***** $g_{_{h}}$
#+BEGIN_SRC python
testes_raiz(residuals['gIh'])
#+END_SRC

#+RESULTS:
:results:

ZIVOT ANDREWS level series
        Zivot-Andrews Results
=====================================
Test Statistic                -10.648
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ZIVOT ANDREWS First differences
        Zivot-Andrews Results
=====================================
Test Statistic                 -6.359
P-value                         0.000
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ADF level series
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                -10.019
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


ADF First differences
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -5.955
P-value                         0.000
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -3.50 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS level series
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -9.023
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -2.75 (1%), -2.13 (5%), -1.82 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS First differences
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -0.608
P-value                         0.470
Lags                               11
-------------------------------------

Trend: Constant
Critical Values: -2.77 (1%), -2.15 (5%), -1.84 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


KPSS em nível
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.095
P-value                         0.611
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


KPSS em primeira diferença
:end:

***** own interest rate

#+BEGIN_SRC python
testes_raiz(residuals['Own Interest rate'])
#+END_SRC

#+RESULTS:
:results:

ZIVOT ANDREWS level series
        Zivot-Andrews Results
=====================================
Test Statistic                -10.062
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ZIVOT ANDREWS First differences
        Zivot-Andrews Results
=====================================
Test Statistic                 -6.787
P-value                         0.000
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ADF level series
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -9.578
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


ADF First differences
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -6.192
P-value                         0.000
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -3.50 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS level series
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -9.510
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -2.75 (1%), -2.13 (5%), -1.82 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS First differences
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -0.955
P-value                         0.312
Lags                               12
-------------------------------------

Trend: Constant
Critical Values: -2.77 (1%), -2.15 (5%), -1.84 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


KPSS em nível
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.047
P-value                         0.897
Lags                                1
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


KPSS em primeira diferença
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.248
P-value                         0.191
Lags                               47
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


Phillips Perron em nível
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                 -9.559
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


Phillips Perron em primeira diferença
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                -34.183
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.50 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.
:end:

** VAR Estimation

VAR: $\Delta \text{own} \sim \Delta g_{I_{h}}$

*** Order selection

#+BEGIN_SRC python 
model = VAR(
    df[["d_Own Interest rate", 'd_gIh']],
)
print(model.select_order(maxlags=15, trend='ct').summary())
#+END_SRC

#+RESULTS:
:results:
 VAR Order Selection (* highlights the minimums)
==================================================
       AIC         BIC         FPE         HQIC
--------------------------------------------------
0       -15.75      -15.64   1.451e-07      -15.70
1       -15.90      -15.69   1.239e-07      -15.82
2       -16.24     -15.92*   8.860e-08      -16.11
3       -16.20      -15.77   9.195e-08      -16.03
4       -16.34      -15.81  7.983e-08*     -16.13*
5       -16.34      -15.69   8.046e-08      -16.08
6       -16.31      -15.56   8.284e-08      -16.01
7       -16.25      -15.39   8.839e-08      -15.90
8       -16.28      -15.32   8.547e-08      -15.89
9       -16.24      -15.17   8.934e-08      -15.81
10      -16.25      -15.07   8.906e-08      -15.77
11     -16.36*      -15.07   7.998e-08      -15.84
12      -16.34      -14.95   8.203e-08      -15.78
13      -16.33      -14.82   8.404e-08      -15.72
14      -16.25      -14.64   9.153e-08      -15.60
15      -16.18      -14.46   9.902e-08      -15.49
--------------------------------------------------
:end:

*** Estimation

#+BEGIN_SRC python
results = model.fit(maxlags=4)
print(results.summary())
#+END_SRC

#+RESULTS:
:results:
  Summary of Regression Results
==================================
Model:                         VAR
Method:                        OLS
Date:           qua, 10, fev, 2021
Time:                     16:48:44
--------------------------------------------------------------------
No. of Equations:         2.00000    BIC:                   -15.9295
Nobs:                     106.000    HQIC:                  -16.1985
Log likelihood:           585.419    FPE:                7.68856e-08
AIC:                     -16.3818    Det(Omega_mle):     6.53222e-08
--------------------------------------------------------------------
Results for equation d_Own Interest rate
=========================================================================================
                            coefficient       std. error           t-stat            prob
-----------------------------------------------------------------------------------------
const                         -0.000226         0.001274           -0.177           0.859
L1.d_Own Interest rate         0.027513         0.107907            0.255           0.799
L1.d_gIh                       0.054066         0.060740            0.890           0.373
L2.d_Own Interest rate        -0.010537         0.110336           -0.095           0.924
L2.d_gIh                       0.102373         0.074290            1.378           0.168
L3.d_Own Interest rate         0.083036         0.123557            0.672           0.502
L3.d_gIh                       0.103936         0.067756            1.534           0.125
L4.d_Own Interest rate         0.273825         0.122986            2.226           0.026
L4.d_gIh                       0.054389         0.053672            1.013           0.311
=========================================================================================

Results for equation d_gIh
=========================================================================================
                            coefficient       std. error           t-stat            prob
-----------------------------------------------------------------------------------------
const                         -0.003136         0.002158           -1.454           0.146
L1.d_Own Interest rate        -0.416556         0.182812           -2.279           0.023
L1.d_gIh                      -0.791871         0.102904           -7.695           0.000
L2.d_Own Interest rate        -1.178970         0.186928           -6.307           0.000
L2.d_gIh                      -0.692994         0.125859           -5.506           0.000
L3.d_Own Interest rate        -0.582157         0.209325           -2.781           0.005
L3.d_gIh                      -0.352853         0.114791           -3.074           0.002
L4.d_Own Interest rate        -0.442090         0.208359           -2.122           0.034
L4.d_gIh                      -0.355391         0.090929           -3.908           0.000
=========================================================================================

Correlation matrix of residuals
                       d_Own Interest rate     d_gIh
d_Own Interest rate               1.000000 -0.394272
d_gIh                            -0.394272  1.000000
:end:


*** Impsulse respose

**** Orthoganalized

#+BEGIN_SRC python :results graphics file :file ./figs/Impulse_VAROrth.png
p = results.irf(20).plot(orth=True)
sns.despine()

p.savefig("./figs/Impulse_VAROrth.png", dpi = 300, bbox_inches = 'tight',
    pad_inches = 0.0, transparent = False,)

plt.close('all')
#+END_SRC

#+RESULTS:
[[file:./figs/Impulse_VAROrth.png]]

**** Non-Orthoganalized

#+BEGIN_SRC python :results graphics file :file ./figs/Impulse_VAR.png
p = results.irf(20).plot(orth=False)
p.suptitle("")
sns.despine()


p.savefig("./figs/Impulse_VAR.png", dpi = 300, bbox_inches = 'tight',
    pad_inches = 0.0, transparent = False,)
plt.close('all')
#+END_SRC

#+RESULTS:
[[file:./figs/Impulse_VAR.png]]

**** Cumulative effect

#+BEGIN_SRC python :results graphics file :file ./figs/Impulse_Cum.png
p = results.irf(20).plot_cum_effects(orth=True)
sns.despine()
p.savefig("./figs/Impulse_Cum.png", dpi = 300)
#+END_SRC

#+RESULTS:
[[file:./figs/Impulse_Cum.png]]


*** FEVD
#+BEGIN_SRC python :results graphics file :file ./figs/FEVD_VAR.png
p = results.fevd(20).plot()
sns.despine()
p.savefig("./figs/FEVD_VAR.png", dpi = 300)
#+END_SRC

#+RESULTS:
[[file:./figs/FEVD_VAR.png]]
*** Granger-Causality test
#+BEGIN_SRC python
series = residuals.columns
print(results.test_causality(causing = series[0], caused=series[1]).summary())
print(results.test_causality(causing = series[1], caused=series[0]).summary())
#+END_SRC

#+RESULTS:
:results:
:end:


*** Post estimation
**** Residuals auto-correlation
#+BEGIN_SRC python
results.plot_acorr(nlags = 20)
sns.despine()
plt.show()
plt.close()
#+END_SRC

#+RESULTS:
:results:
    caused_ind = [util.get_index(self.names, c) for c in caused]
  File "/home/gpetrini/.local/lib/python3.8/site-packages/statsmodels/tsa/vector_ar/var_model.py", line 1784, in <listcomp>
    caused_ind = [util.get_index(self.names, c) for c in caused]
  File "/home/gpetrini/.local/lib/python3.8/site-packages/statsmodels/tsa/vector_ar/util.py", line 254, in get_index
    result = lst.index(name)
ValueError: 'gIh' is not in list
>>>
:end:
**** Model stability
#+BEGIN_SRC python
print("Estável:", results.is_stable(verbose=True))
#+END_SRC

#+RESULTS:
:results:
Eigenvalues of VAR(1) rep
0.6031315796912359
0.7065740604925873
0.7065740604925873
0.7464606302801982
0.7464606302801982
0.6595330472590406
0.8137205059477957
0.8137205059477957
Estável: True
:end:


**** Visual inspection
#+BEGIN_SRC python
residuals = analise_residuos(results=results)
#+END_SRC

#+RESULTS:
:results:
AUTOCORRELAÇÃO RESIDUAL: PORTMANTEAU

Portmanteau-test for residual autocorrelation. H_0: residual autocorrelation up to lag 15 is zero. Conclusion: fail to reject H_0 at 5% significance level.
========================================
Test statistic Critical value p-value df
----------------------------------------
         51.19          60.48   0.212 44
----------------------------------------

AUTOCORRELAÇÃO RESIDUAL: PORTMANTEAU AJUSTADO

Adjusted Portmanteau-test for residual autocorrelation. H_0: residual autocorrelation up to lag 15 is zero. Conclusion: fail to reject H_0 at 5% significance level.
========================================
Test statistic Critical value p-value df
----------------------------------------
         55.84          60.48   0.109 44
----------------------------------------

LJUNGBOX

H0: autocorrelations up to lag k equal zero
H1: autocorrelations up to lag k not zero
Box-Pierce:  False
Testing for  D_OWN INTEREST RATE . Considering a significance level of 5.0 %
/home/gpetrini/.local/lib/python3.8/site-packages/statsmodels/stats/diagnostic.py:524: FutureWarning: The value returned will change to a single DataFrame after 0.12 is released.  Set return_df to True to use to return a DataFrame now.  Set return_df to False to silence this warning.
  warnings.warn(msg, FutureWarning)
p-value = 0.9936657651605834
Reject H0 on lag  1 ?  False

p-value = 0.9532942411607932
Reject H0 on lag  2 ?  False

p-value = 0.9372394031653212
Reject H0 on lag  3 ?  False

p-value = 0.9475077053483082
Reject H0 on lag  4 ?  False

p-value = 0.923728312676192
Reject H0 on lag  5 ?  False

p-value = 0.9433151078232945
Reject H0 on lag  6 ?  False

p-value = 0.7677479216264478
Reject H0 on lag  7 ?  False

p-value = 0.6897935175949668
Reject H0 on lag  8 ?  False

p-value = 0.6703161073268695
Reject H0 on lag  9 ?  False

p-value = 0.6212750708549971
Reject H0 on lag  10 ?  False

p-value = 0.695713683986997
Reject H0 on lag  11 ?  False

p-value = 0.648377705928423
Reject H0 on lag  12 ?  False



Testing for  D_GIH . Considering a significance level of 5.0 %
p-value = 0.2630124312990188
Reject H0 on lag  1 ?  False

p-value = 0.2968361758158871
Reject H0 on lag  2 ?  False

p-value = 0.34908891398183817
Reject H0 on lag  3 ?  False

p-value = 0.6503088381838034
Reject H0 on lag  4 ?  False

p-value = 2.6677300651893336
Reject H0 on lag  5 ?  False

p-value = 2.7045180260466166
Reject H0 on lag  6 ?  False

p-value = 2.719802469699149
Reject H0 on lag  7 ?  False

p-value = 4.145628089650675
Reject H0 on lag  8 ?  False

p-value = 4.2702372657792225
Reject H0 on lag  9 ?  False

p-value = 4.370535403813121
Reject H0 on lag  10 ?  False

p-value = 8.512718885625794
Reject H0 on lag  11 ?  False

p-value = 10.137636303787597
Reject H0 on lag  12 ?  False




BOXPIERCE

H0: autocorrelations up to lag k equal zero
H1: autocorrelations up to lag k not zero
Box-Pierce:  True
Testing for  D_OWN INTEREST RATE . Considering a significance level of 5.0 %
p-value = 0.993754358398482
Reject H0 on lag  1 ?  False

p-value = 0.9549842613606685
Reject H0 on lag  2 ?  False

p-value = 0.9410348767973901
Reject H0 on lag  3 ?  False

p-value = 0.9519814611221903
Reject H0 on lag  4 ?  False

p-value = 0.9322607991724536
Reject H0 on lag  5 ?  False

p-value = 0.9511237631972581
Reject H0 on lag  6 ?  False

p-value = 0.8022500063405594
Reject H0 on lag  7 ?  False

p-value = 0.7384560766480192
Reject H0 on lag  8 ?  False

p-value = 0.7267584471916546
Reject H0 on lag  9 ?  False

p-value = 0.6898947167119986
Reject H0 on lag  10 ?  False

p-value = 0.7593373676867421
Reject H0 on lag  11 ?  False

p-value = 0.7262432361489415
Reject H0 on lag  12 ?  False



Testing for  D_GIH . Considering a significance level of 5.0 %
p-value = 0.2630124312990188
Reject H0 on lag  1 ?  False

p-value = 0.2968361758158871
Reject H0 on lag  2 ?  False

p-value = 0.34908891398183817
Reject H0 on lag  3 ?  False

p-value = 0.6503088381838034
Reject H0 on lag  4 ?  False

p-value = 2.6677300651893336
Reject H0 on lag  5 ?  False

p-value = 2.7045180260466166
Reject H0 on lag  6 ?  False

p-value = 2.719802469699149
Reject H0 on lag  7 ?  False

p-value = 4.145628089650675
Reject H0 on lag  8 ?  False

p-value = 4.2702372657792225
Reject H0 on lag  9 ?  False

p-value = 4.370535403813121
Reject H0 on lag  10 ?  False

p-value = 8.512718885625794
Reject H0 on lag  11 ?  False

p-value = 10.137636303787597
Reject H0 on lag  12 ?  False




NORMALIDADE

normality (skew and kurtosis) test. H_0: data generated by normally-distributed process. Conclusion: reject H_0 at 5% significance level.
========================================
Test statistic Critical value p-value df
----------------------------------------
         49.85          9.488   0.000  4
----------------------------------------

HOMOCEDASTICIDADE

H0: Residuals are homoscedastic
H1: Residuals are heteroskedastic
Testing for  D_OWN INTEREST RATE
/home/gpetrini/.local/lib/python3.8/site-packages/statsmodels/stats/diagnostic.py:622: FutureWarning: The default value of nlags is changing.  After 0.12, this value will become min(10, nobs//5). Directly setmaxlags or period to silence this warning.
  warnings.warn("The default value of nlags is changing.  After 0.12, "
/home/gpetrini/.local/lib/python3.8/site-packages/statsmodels/stats/diagnostic.py:645: FutureWarning: autolag is deprecated and will be removed after 0.12. Model selection before testing fails to control test size. Set autolag to False to silence this warning.
  warnings.warn("autolag is deprecated and will be removed after 0.12. "
LM statistic:  1.7890934997621706
LM p-value:  0.18103664996914828
Reject H0?  False
F statistic:  1.7854375736451698
F p-value:  0.18442759159846756
Reject H0?  False


Testing for  D_GIH
LM statistic:  1.0833069510599869
LM p-value:  0.2979589446764947
Reject H0?  False
F statistic:  1.0737506428022083
F p-value:  0.3025264545817077
Reject H0?  False
:end:

#+BEGIN_SRC python
series = results.names
sns.set_context('talk')
ax = sns.jointplot(
    x = series[0], 
    y = series[1], 
    data = residuals, color = 'darkred', kind="reg", 
)
plt.show()
plt.close('all')
#+END_SRC

#+RESULTS:
:results:
:end:

***** All residuals
#+BEGIN_SRC python :results graphics file :file ./figs/Residuals_4VAR.png
g = sns.PairGrid(residuals, diag_sharey=False, height = 5, aspect=(8/5))
g.map_lower(sns.kdeplot, color = 'darkred')
g.map_upper(sns.scatterplot, color = 'darkred')
g.map_diag(sns.kdeplot, lw=3, color = 'darkred')
g.savefig("./figs/Residuals_4VAR.png", dpi = 600, )
plt.close('all')
#+END_SRC

#+RESULTS:
[[file:./figs/Residuals_4VAR.png]]
***** Residuals vs Residuals
#+BEGIN_SRC python :results graphics
series = results.names
for serie in series:
    sns.scatterplot(x = residuals[serie], y = residuals[serie]**2)
    sns.despine()
    
    sns.scatterplot(
    y = residuals[serie], 
    x = residuals[serie].shift(-1), 
    color = 'darkred' 
    )
    sns.despine()
    plt.xlabel(f"{serie}(-1)")

plt.close('all')
#+END_SRC

#+RESULTS:
***** Lags vs Lags
#+BEGIN_SRC python :results graphics file :file ./figs/VEC_Defasagens.png
plot_lags(results=results)
#+END_SRC

#+RESULTS:
[[file:./figs/VEC_Defasagens.png]]

**** Residuals stationarity
***** $g_{_{h}}$
#+BEGIN_SRC python
testes_raiz(residuals['d_gIh'])
#+END_SRC

#+RESULTS:
:results:

ZIVOT ANDREWS level series
        Zivot-Andrews Results
=====================================
Test Statistic                -10.744
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ZIVOT ANDREWS First differences
        Zivot-Andrews Results
=====================================
Test Statistic                 -6.183
P-value                         0.001
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ADF level series
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                -10.286
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


ADF First differences
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -5.695
P-value                         0.000
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -3.50 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS level series
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -0.926
P-value                         0.324
Lags                                6
-------------------------------------

Trend: Constant
Critical Values: -2.76 (1%), -2.14 (5%), -1.83 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS First differences
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -0.788
P-value                         0.385
Lags                               11
-------------------------------------

Trend: Constant
Critical Values: -2.77 (1%), -2.15 (5%), -1.84 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


KPSS em nível
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.143
P-value                         0.411
Lags                                1
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


KPSS em primeira diferença
:end:

***** own interest rate

#+BEGIN_SRC python
testes_raiz(residuals['d_Own Interest rate'])
#+END_SRC

#+RESULTS:
:results:

ZIVOT ANDREWS level series
        Zivot-Andrews Results
=====================================
Test Statistic                -10.177
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ZIVOT ANDREWS First differences
        Zivot-Andrews Results
=====================================
Test Statistic                 -6.843
P-value                         0.000
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -5.28 (1%), -4.81 (5%), -4.57 (10%)
Null Hypothesis: The process contains a unit root with a single structural break.
Alternative Hypothesis: The process is trend and break stationary.


ADF level series
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -9.659
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


ADF First differences
   Augmented Dickey-Fuller Results
=====================================
Test Statistic                 -6.199
P-value                         0.000
Lags                                9
-------------------------------------

Trend: Constant
Critical Values: -3.50 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS level series
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -9.161
P-value                         0.000
Lags                                0
-------------------------------------

Trend: Constant
Critical Values: -2.75 (1%), -2.13 (5%), -1.82 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


DFGLS First differences
      Dickey-Fuller GLS Results
=====================================
Test Statistic                 -9.567
P-value                         0.000
Lags                                2
-------------------------------------

Trend: Constant
Critical Values: -2.75 (1%), -2.13 (5%), -1.82 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


KPSS em nível
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.045
P-value                         0.904
Lags                                1
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


KPSS em primeira diferença
    KPSS Stationarity Test Results
=====================================
Test Statistic                  0.232
P-value                         0.214
Lags                               43
-------------------------------------

Trend: Constant
Critical Values: 0.74 (1%), 0.46 (5%), 0.35 (10%)
Null Hypothesis: The process is weakly stationary.
Alternative Hypothesis: The process contains a unit root.


Phillips Perron em nível
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                 -9.644
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.


Phillips Perron em primeira diferença
     Phillips-Perron Test (Z-tau)
=====================================
Test Statistic                -34.807
P-value                         0.000
Lags                               13
-------------------------------------

Trend: Constant
Critical Values: -3.49 (1%), -2.89 (5%), -2.58 (10%)
Null Hypothesis: The process contains a unit root.
Alternative Hypothesis: The process is weakly stationary.
:end:


* VECM :ignore:

** Houses' own interest rate and residential investment growth rate in the US	Economy
#+LATEX: \label{sc:own} 

In this subsection, we describe the relationship between residential investment growth rate ($g_{I_h}$) and houses' own interest rate ($own$) as proposed by textcite:teixeira_crescimento_2015. 
Next, we will present the hypothesis to be tested on the Section ref:sec:estimation. To obtain this relationship, we deflate mortgage interest rate ($r_{mo}$) by real estate inflation ($\pi$) as follows:

#+begin_export latex
$$
g_{I_h} = \phi_0 - \phi_1\cdot \overbrace{\left(\frac{1+r_{mo}}{1+\pi} - 1\right)}^{own}
$$

\begin{equation}
g_{I_h} = \phi_0 - \phi_1\cdot own
\end{equation}
#+end_export

where $\phi_0$ stands for long-term determinants (/e.g./ demographic factors, housing and credit policies, etc.) while $\phi_1$ captures the demand for real estate arising from expectations of capital gains resulting from speculation with the existing dwellings stock. 
This particular real interest rate is the most relevant for households since it is the real cost in real estate from buying real estate  \cite[p.~53]{teixeira_crescimento_2015}.

Figure ref:propria_investo shows how this deflation procedure is more adequate than a general price index --- as \textcite[p.~143--6]{fair_macroeconometric_2013} does --- to describe the housing dynamics. It worth noting that during a houses' bubble period, it is real estate inflation that governs own's interest rate dynamics.
Therefore, the lower this rate is, the greater the capital gains (in real estate) for speculating with real estate will be. This negative relation between houses' own interest rate and residential investment is shown in Figure ref:propria_investo in which this particular real interest rate has been gradually decreased over the real estate boom (2002-5).

Despite shedding light on some relevant relationships, \citeauthor*{teixeira_crescimento_2015}'s \citeyear{teixeira_crescimento_2015} proposition was not evaluated econometrically and this will be done in Section \ref{sec:estimation}. To do so, we assume the following long-run relationship:

#+begin_export latex
\begin{equation}
g_{I_{h_{t}}} = \phi_0 - \phi_1\cdot own_t
\end{equation}
#+end_export

therefore, if these time-series are co-integrated, we specify the short-run adjustment process through the following VECM:
#+begin_export latex
\begin{equation}
\begin{cases}
\Delta own_t = \delta_{1} + \alpha_1\left(g_{I_{h_{t-1}}} - \phi_0 + \phi_1\cdot own_{t-1}\right) + {\sum^{N=4}_{i=1}}\beta_{1,i}\cdot \Delta g_{I_{h_{t-i}}} +
\sum^{N=4}_{i=1}\gamma_{1,i}\cdot \Delta own_{t-i} +\varepsilon_{t,1}
\\
\Delta g_{Z_{t}} = \delta_{2} + \alpha_2\left(g_{I_{h_{t-1}}} - \phi_0 + \phi_1\cdot own_{t-1}\right) + \sum^{N=4}_{i=1}\beta_{2,i}\cdot \Delta g_{I_{h_{t-i}}} +
\sum^{N=4}_{i=1}\gamma_{2,i}\cdot \Delta own_{t-i} +\varepsilon_{t,2}
\end{cases}
\end{equation}
#+end_export

where $\delta_s$ indicate linear trend (level);
$\alpha_{is}$ are the error correction coefficients; 
$\beta_s$ and $\gamma_s$ are coefficients associated with lagged $g_{I_h}$ and $own$ respectively and; $\varepsilon_s$ are the residuals.
Based on \textcite{teixeira_crescimento_2015}, we depict the expected results in Table \ref{resultados_esperados} below:

\input{./tabs/hypothesis.tex}

** Data and estimation strategy
#+LATEX: \label{sec:estimation}


In this section, we employ a model to test whether or not houses own rate of interest describes residential investment growth rate dynamics[fn::Scripts are available under request.].
Our sample period (1992:Q1 to 2019:Q1) starts after institutional changes (FDIC e
FIRREA) due to the Savings and Loans crisis (see Table ref:structbreak in appendix ref:appen:A for structural break tests).
We rely on the following  quarterly seasonally adjusted data: (i) 30-Year fixed mortgage interest rate (MORTGAGE30US, resampled by end of period), private residential investment (PRFI, growth rate as percent change from the previous quarter) and Case-Shiller home price index
(CSUSHPISA, resampled by end of period). Figure ref:propria_investo  shows the original series.

#+begin_export latex
\begin{figure}[htb]
	\centering
	\caption{Residential investment growth rate vs. Houses Own interest rate}
	\label{propria_investo}
	\includegraphics[width=\textwidth]{./figs/TxPropria_Investo.png}
	\caption*{\textbf{Source:} U.S. Bureau of Economic Analysis, Authors' elaboration}
\end{figure}
#+end_export


Next, we applied textcite:yeo_new_2000 transformation since these series are volatile. We use this procedure instead of a standard textcite:box_analysis_1964 transformation  because it can be applied to non-positive values.
Then, we employ standard unit root tests (see Table ref:unitroot in appendix ref:appen:A) as well as textcite:johansen_estimation_1991 procedure to assess whether houses' own interest rate and residential investment growth rate share a common long-run trend (see Table ref:Johansen in appendix ref:appen:A).
Our series are co-integrated at 5% significance level which allows us to estimate a error correction model and evaluate the previous hypothesis cite:enders_applied_2014.

#+begin_export latex
\begin{figure}[htb]
	\centering
	\caption{Time-series with \textcite{yeo_new_2000} transformation}
	\label{YeoJhonson}
	\includegraphics[width=\textwidth]{./figs/YeoJohnson_All.png}
	\caption*{\textbf{Source:} U.S. Bureau of Economic Analysis, Authors' elaboration}
\end{figure}
#+end_export




The next step is to define the model order. According to usual information criteria, both first and forth lags are eligible (see Table ref:criterios in appendix ref:appen:A).
Although parsimonious, we argue that the first lag has no empirical support.
Considering the average construction time (from approval to completion), we should include at least the second lag in order to incorporate homes built for capital gains purposes which only take place once the construction is completed (see Figure ref:meses).

#+begin_export latex
\begin{figure}[H]
	\centering
	\caption{Average construction time (approval to completion) of properties for a family unit by construction purposes except manufactured houses (1976-2018)}
    \label{meses}
	\includegraphics[width=\textwidth]{./figs/Meses_construcao.png}
	\caption*{\textbf{Source:} Survey of Construction (SOC), Authors' elaboration}
\end{figure}
#+end_export

This procedure, however, it is not enough to determine the model lag order selection.
Since residential investment (newly constructed homes) is significantly smaller than existing housing stock, we verify an price-effect even if the construction is unfinished[fn::textcite:poterba_tax_1984, for instance, suggests that the time that houses takes to be sold should be include.].
We argue that this price effect is a result of future real estate inflation.
Such dynamic could be captured by the *expected* houses' own interest rate.
However, such series does not exist.
So, we use lagged houses' own interest rate as a first approximation to the expected one[fn::This procedure is similar to textcite:keynes_general_1937 "practical theory of the future" in which decision-making process for buying a new property depends on expectations/conventions based on past observations.
In summary, in the absence of a series for the expected own interest rate, the lag of this variable will be used as a proxy for the future one.
].

In order to display the relation between lagged own interest rate and current residential investment growth rate, Figure \ref{defasagens} depicts one variable of interest against the other variable lagged according to lags that minimize the information criteria (1 and 4 respectively)[fn::Similar data plot can be seen in \textcite[p.~16]{girardi_autonomous_2015}.].
This simple procedure allows checking if there is any relationship between the expected own interest rate (in this case, lagged effective rate) and residential investment growth rate[fn::In order to consider non-linearities, we presented quadratic regression between variables of interest.].
In the same Figure, we verify the non-occurrence of the inverse relationship from residential investment to own interest rate.
Since residential investment (flow) is much lower than the existing stock of dwellings, it is expected that such relationship does not exist.
In summary, speculation with the dwellings stock generates inflation of these assets, which affects the construction of new houses (flow) and not the other way round[fn::It is worth noting a particular aspect of house price formation: land scarcity. As a consequence, speculation with residences is, in the end, speculation with land (the only scarce resource involved in its production) and, therefore, it is relevant for speculation with the dwellings stock. 
	\textcite[p.~349, emphasis added]{leamer_housing_2007} points out this particularity as follows:
	@@latex:\begin{quotation}@@
		It’s not the structure that has a volatile price; *it's the land*. Where there is plenty of buildable land, the response to an increase is demand for homes is mostly to build more, not to increase prices. Where there is little buildable land, the response to an increase in demand for homes is mostly a price increase, sufficient to discourage buyers enough to reequilibrate the supply and demand.
	@@latex:\end{quotation}@@].

#+begin_export latex
\begin{figure}
	\centering
	\caption{Dispersion between houses' own interest rate and residential investment growth: lags selected based on information criteria}
	\label{defasagens}
	\includegraphics[height=.4\textheight]{./figs/VEC_Defasagens.png}
	\caption*{\textbf{Source:} Authors' elaboration}
\end{figure}
#+end_export

Considering this theoretical and econometric discussion of model order specification, we estimate a four lag VEC  (see Table ref:Estimacao)[fn::	In addition to being theoretically based, this lag also generates homoscedastic residuals without serial auto-correlation (see Table ref:testes_resduos in Appendix ref:appen:A).]. 
#+latex: % Figure ref:residuos displays an inspection of the residuals while
Table ref:testes_resduos in Appendix ref:appen:A presents a few residual tests to check the model's specification while Table ref:tab:robust presents some robustness check.
On the following subsection, we analyze the results and compare with the theoretical expected ones presented in Table ref:resultados_esperados above.  




** Estimation results
#+LATEX: \label{sec:results}

According to parameters presented in Table ref:Estimacao, we find statistically significant co-integration  coefficients for both equations. 
Therefore, both variables share a (negative) long-run trend (validating hypotheses 1 and 4).
The short-term relationship between $own$ and $g_{Ih}$ ($\beta_{1, is}$ coefficients) are not statistically significant at 5%[fn::The expected result (7) can also be validated from the inspection of Table ref:Estimacao in which only the fourth lag of own interest rate equation is statistically significant.].
In addition, coefficients $\gamma_{2,s}$ are negative and statistically significant at 5%, supporting hypothesis 6 (see Table  ref:Estimacao).
We also find statistically significant coefficients related to demand for houses for non-speculative reasons ($\phi_0$), validating proposition 5.
On the other hand, the error correction parameter is statistically significant only for the residential investment growth rate equation.
In this sense, $own$ is weakly exogenous compared to $g_{I_h}$ while houses' own interest rate Granger-causes $g_{I_h}$, supporting the hypothesis (2) and (3).
In conclusion, our estimation results are in line with the hypothesis presented above and can be summarized as follows: houses' own interest rate determines --- but is not determined by --- residential investment growth rate and these variables present a negative long-term relationship (are co-integrated).

#+begin_export latex
\begin{table}[h!]
	\caption{Estimation parameters}
	\centering
	\input{./tabs/parameters.tex}
	\caption*{\textbf{Source:} Authors' elaboration}
\end{table}
#+end_export
#+begin_export latex :exports none
\begin{figure}
	\centering
	\caption{Inspection of estimation residuals}
	\label{residuos}
	\includegraphics[width=.9\textwidth]{./figs/Residuals_4VECM.png}
	\caption*{\textbf{Source:} Authors' elaboration}
\end{figure}
#+end_export

Figure ref:fevd display the forecast error variance decomposition (FEVD) which reports houses own interest rate in describing residential investment growth rate dynamics[fn:: It is important to note that the number of variables (two) used generates similar  of a Structural VEC, which means that Choleski's decomposition is sufficient to analyze the (orthogonalized) impulse response function.].
We report that own interest rate has  depicted  $g_{Ih}$ --- while the reverse is not valid --- after the first quarter.
In addition, we find that such contribution is greater than 50% beyond the third quarter.
Therefore, houses' own interest rate is explained mainly by itself and explains $g_{I_h}$ considerably.

#+begin_export latex
\begin{figure}[H]
	\centering
	\caption{Forecast error variance decomposition (FEVD)}
	\label{fevd}
	\includegraphics[height=.4\textheight]{./figs/FEVD_VECMpython_TxPropria.png}
	\caption*{\textbf{Source:} Authors' elaboration}
\end{figure}
#+end_export

Next, we analyze the orthoganilized impulse response function (Figure ref:irf).
In summary, we report a stable system since the increase in $g_{I_h}$ on itself are dampened over time while equivalent shock on own interest rate has a non-explosive permanent effect.
On the other hand, an increase in $g_{I_h}$ has a null effect over $own$.
The most relevant result reported in Figure ref:irf is the considerable and lasting negative effect due to an increase in own interest rate over $g_{I_h}$, validating \citeauthor*{teixeira_crescimento_2015}'s \citeyear{teixeira_crescimento_2015} proposition.
In short, our results shows that an increase in mortgage interest rate (equivalent to an increase in houses' own interest rate) has a negative and persistent effect on residential investment growth rate while an increase in real estate inflation  has an opposite effect.
#+begin_export latex
\begin{figure}[H]
	\centering
	\caption{Orthogonalized Impulse Response Function}
	\label{irf}
	\includegraphics[height=.4\textheight]{./figs/Impulse_VECM.png}
	\caption*{\textbf{Source:} Authors' elaboration}
\end{figure}
#+end_export

** Comparison with previous studies

In this section,  we contrast our findings with those obtained by the literature.
At this stage, we restrict the comparison with  textcite:gauger_residential_2003 and textcite:arestis_residential_2015 since we share the same topic.
Similar to textcite:gauger_residential_2003, we report that mortgage interest rate is relevant for residential investment.
Despite some theoretical differences, our estimations are in line with textcite:arestis_residential_2015 (at least for the US): house prices are relevant to describe residential investment growth rate.
However, they report insignificant coefficients for mortgages nominal interest rate which is at odds with our conclusions.
In summary, our estimation reports that houses' own interest rate has a prominent role in describing residential investment growth rate movements. 
It is worth noting that despite the amplitude of VEC order, our model is parsimonious considering the number of variables used.
Thus, we conclude that our estimation depicts residential investment growth rate satisfactorily.
On the following section we present some concluding remarks.

#+begin_comment
%It worth remembering that one of the authors' hypotheses is that residential investment depends on disposable income (is induced expenditure).
%However, the authors themselves find that such results are not statistically significant for the US. Therefore, we can compare this result with our model.
#+end_comment
